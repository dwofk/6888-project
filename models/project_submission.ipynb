{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.888 Final Project - Winograd Transforms\n",
    "\n",
    "### Madeleine Waller & Diana Wofk\n",
    "\n",
    "In this project, we use as our baseline this course's lab 4 WS 2D Architecture.  We build on this architecture in the following steps: <br />\n",
    "- Include the baseline architecture with added energy computations for performance comparison.\n",
    "- Redesign the PE array to perform element wise multiplications of the transformed weights/ifmaps (rather than convolution). Implement off chip pre/post processing of ifmaps, weights, and ofmaps.\n",
    "- Move the post processing (reverse transform of ofmaps) onto the chip via a specialized ALU array, similar to the PE array.\n",
    "- Move the pre processing on chip (in addition to the post processing), using a similar specialized ALU array to transform both the weights and ifmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsim.simulator import run_tb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline WS 2D Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifmap glb depth: 16\n",
      "psum glb depth: 32\n",
      "weight glb depth: 0\n",
      "ifmap:  [[[  3 -10  15  11]\n",
      "  [ -6  -3   3  -2]\n",
      "  [-20  10  -2 -11]\n",
      "  [ -5  23  10   0]]\n",
      "\n",
      " [[  7   0   8  -9]\n",
      "  [  0   1  10 -16]\n",
      "  [ -6 -20  -6  -7]\n",
      "  [ -6  13 -16   9]]\n",
      "\n",
      " [[  1  -4   1   5]\n",
      "  [ -1  -1   8  -8]\n",
      "  [  6  -5  -3  -3]\n",
      "  [ -5   1   9   3]]\n",
      "\n",
      " [[-16 -11   0   0]\n",
      "  [  6  13  -2  24]\n",
      "  [  3  15   0 -19]\n",
      "  [  0   2  -2  11]]]\n",
      "weights:  [[[[  5   3   8   2   4  -8   4   3]\n",
      "   [  3   2 -20  13   0 -13  12  -2]\n",
      "   [  7  -8  -8  -6  23  -2   3   0]\n",
      "   [  0  10   2   1  -3  -8  18 -12]]\n",
      "\n",
      "  [[  0  -1  19   5  -1   8  -7   1]\n",
      "   [  1  -6  -3 -16   2  -8  12  17]\n",
      "   [-29 -10 -10  -1  -7   1   0  -5]\n",
      "   [  9   1  -4  -8   0   8 -16  -6]]\n",
      "\n",
      "  [[-18   0   5 -25   3  17   5  -4]\n",
      "   [  4  -1   0   8  -4  -7  -1   5]\n",
      "   [-21   4  -2   2   1   9  15   6]\n",
      "   [  0 -17 -16  -1   2 -24   4   3]]]\n",
      "\n",
      "\n",
      " [[[ -1  -1  16  -3  -1  -2  -4  10]\n",
      "   [ 28  -3   0  -8  -8  10   3   1]\n",
      "   [  4  15  15 -11  16 -10   0   8]\n",
      "   [-15   2  -2 -18   9  14 -17   5]]\n",
      "\n",
      "  [[ -6   1   1 -12   6   3  -2   5]\n",
      "   [  9   6   9  -5  -5   8  12  -6]\n",
      "   [-12   2   0   1  -6 -26   2 -10]\n",
      "   [  3   5 -13   7   9  -3  -3  -1]]\n",
      "\n",
      "  [[ -2   1 -13   5 -15   6   1 -16]\n",
      "   [ -8 -12  13   8  20   9   8   0]\n",
      "   [  2  -5 -12  14  10   4  -8   3]\n",
      "   [-27   2   5  11   3  -4  -1  -1]]]\n",
      "\n",
      "\n",
      " [[[  6   3  -3  -3 -19   0  18  16]\n",
      "   [ 14   2   6  -7   0 -11  -4  -1]\n",
      "   [ 10   0 -18 -12  -2   4   7  -6]\n",
      "   [ 10  12   5  -7  16  -1   5   9]]\n",
      "\n",
      "  [[ -7  -2 -17  -5   3 -12  -1  -9]\n",
      "   [  6  14  -4  -5  -4  -1   6 -18]\n",
      "   [  1   3  -3  10   2 -11   0   8]\n",
      "   [  0   0  -2  -3   4  -9   6  -2]]\n",
      "\n",
      "  [[ -4   0 -10  12   2   5  12  -1]\n",
      "   [  7   1   2   2   5   1   9  -1]\n",
      "   [ -3  -3  10   3  -3   6  -4  -8]\n",
      "   [ 17  -1   7   4  -7   5  -9   8]]]]\n",
      "bias:  [-11   2  -4   3  -5  13  11  -7]\n",
      "(4, 4, 4) (3, 3, 4, 8) (8,)\n",
      "reference:  [[[-506   38 -376  115  214 -634 -118 -176]\n",
      "  [-348   58  298 -451  415 -244 -261  568]\n",
      "  [ 186 -716  355  476  217  457  206  293]\n",
      "  [ 221   97  -79  215 -453  285  647 -960]]\n",
      "\n",
      " [[-238 -219 -160   30  -89  105 -299 -349]\n",
      "  [ 681  507  269  146 -325 -804  173  164]\n",
      "  [-284 -423   69  252  107 -621  569  462]\n",
      "  [-507 -295 -773  290 -179  149  471  446]]\n",
      "\n",
      " [[ 200   49  515  524  -67  805   -6  624]\n",
      "  [-849   70 -329 -213  526 -370  277 -849]\n",
      "  [1373  253   65  399  610 -537 -510  293]\n",
      "  [ 290 -156  337 -384 -434 -256 -323   20]]\n",
      "\n",
      " [[-924   15  224  689  153  261  -38 -226]\n",
      "  [-109   36 -278  -83  480  394  402 -394]\n",
      "  [-270 -133  516 -450   99  686 -199  234]\n",
      "  [ 527 -107  -77  169 -290  -42  254  -47]]]\n",
      "image size: (4, 4)\n",
      "filter size: (3, 3)\n",
      "in chn: 4\n",
      "out chn: 8\n",
      "PE array size: 32\n",
      "/tb: \n",
      "\tpe_comp_energy: 9216\n",
      "\tdram_mem_acc: 608\n",
      "\tglb_mem_acc: 2944\n",
      "\trf_mem_acc: 4608\n",
      "\ttotal_mem_acc: 8160\n",
      "\ttotal_noc_multicasts: 3168\n",
      "\tdram_energy: 121600\n",
      "\tglb_energy: 17664\n",
      "\trf_energy: 4608\n",
      "\tdata_energy: 143872\n",
      "\tcomp_energy: 9216\n",
      "\ttotal_energy: 153088\n",
      "/tb/chip: \n",
      "\tdram_rd: 480\n",
      "\tdram_wr: 128\n",
      "\tpe_mac: 4608\n",
      "\tpe_chn_pop: 3456\n",
      "\tpe_chn_push: 4608\n",
      "\tpe_rf_rd: 4320\n",
      "\tpe_rf_wr: 288\n",
      "/tb/chip/ifmap_glb: \n",
      "\tsize: (16, 4)\n",
      "\tifmap_glb_rd: 576\n",
      "\tifmap_glb_wr: 64\n",
      "/tb/chip/psum_glb: \n",
      "\tsize: (32, 4)\n",
      "\tpsum_glb_rd: 1152\n",
      "\tpsum_glb_wr: 1152\n",
      "/tb/chip/weight_glb: \n",
      "\tsize: (0, 0)\n",
      "\tweight_glb_rd: 0\n",
      "\tweight_glb_wr: 0\n",
      "/tb/chip/weight_noc: \n",
      "\tnoc_multicast: 288\n",
      "/tb/chip/ifmap_noc: \n",
      "\tnoc_multicast: 576\n",
      "/tb/chip/psum_rd_noc: \n",
      "\tnoc_multicast: 1152\n",
      "/tb/chip/psum_wr_noc: \n",
      "\tnoc_multicast: 1152\n",
      "\n",
      "cyc 351: Success\n"
     ]
    }
   ],
   "source": [
    "from ws_2d.tb import WSArchTB\n",
    "\n",
    "ws_tb = WSArchTB()\n",
    "run_tb(ws_tb, verbose=False, dump_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winograd Transform - Pre/Post Processing Off Chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifmap glb depth: 64\n",
      "weight glb depth: 0\n",
      "ifmaps:  [[[ 17  -5  -4  -6]\n",
      "  [ -8 -12   1  -6]\n",
      "  [-13   1 -14  -9]\n",
      "  [  4 -12  18  -5]]\n",
      "\n",
      " [[  4  -4   0  10]\n",
      "  [-21  -6  11  11]\n",
      "  [  0  -7   1 -15]\n",
      "  [-14 -11  10 -15]]\n",
      "\n",
      " [[  4   0  -6  -1]\n",
      "  [ -4  11   4   5]\n",
      "  [  0  18   7   0]\n",
      "  [  4  11 -11  -4]]\n",
      "\n",
      " [[ 12  12 -10  -5]\n",
      "  [ 11   2  15  -6]\n",
      "  [-15 -11  -2   5]\n",
      "  [  1 -11   6   1]]]\n",
      "weights:  [[[[-11  14 -15 -13   0  -8  13  -8]\n",
      "   [-12 -10   0   3   5   0  11   5]\n",
      "   [ 12   2  -2 -12  -6  -7  -3  11]\n",
      "   [  9 -20   0  -4  -9   9  -1  -5]]\n",
      "\n",
      "  [[ 16   5   2   3 -13 -12   9  -5]\n",
      "   [  0 -11   3   2  10  -1   6   8]\n",
      "   [-15  -5 -10   2   3   5  -3 -11]\n",
      "   [-12  -1  11 -20 -15  -4   4  11]]\n",
      "\n",
      "  [[  6  -8   3   9   5   5  -6   6]\n",
      "   [-18  -2  19  -1  25   9  -9  10]\n",
      "   [-10 -11  -3   5   4  20  11  16]\n",
      "   [ -2   1 -19  11  -4  15   5  -5]]]\n",
      "\n",
      "\n",
      " [[[ 13  -4   5  18   0   5  -7   6]\n",
      "   [ -5  11  19 -22 -12  -9   3  -3]\n",
      "   [  5  -6   8  13  -2  -3   0   5]\n",
      "   [  7  -7  -7  -3  16   3   4  -9]]\n",
      "\n",
      "  [[  9  -6   6   7   0   6   8   9]\n",
      "   [ -3  -2   4   7 -10  -1   4  -3]\n",
      "   [  2  14  -3   2  -1  -9  -8  15]\n",
      "   [-11   2   9 -12 -18  13  -1   0]]\n",
      "\n",
      "  [[  0 -12   0  -1  -1  13  -3 -15]\n",
      "   [ -2  -9 -16   4   0  -9  -3  13]\n",
      "   [  6   7   8  -9 -15   3  14  10]\n",
      "   [  6  22 -18  14  -6  16  -9  -8]]]\n",
      "\n",
      "\n",
      " [[[-14  16   3  -2   1  15   7 -13]\n",
      "   [  8  -7  -1  12 -19  -5  -5  -4]\n",
      "   [  6  10  -2   0  18  -6  -6   0]\n",
      "   [ 20  -3  -1  -9   0   1  -1 -12]]\n",
      "\n",
      "  [[ -8   9  19  -7   1 -17  -3 -23]\n",
      "   [ -9   6  -6 -13  -1 -12 -11   9]\n",
      "   [  0  -7   6  32   9 -11  -7   4]\n",
      "   [  6   2 -17  -2  -6  -1   0  -7]]\n",
      "\n",
      "  [[  3   6   2  14  16  -6  -3  -2]\n",
      "   [ -3  -2   8   6 -13  10  -6  -3]\n",
      "   [  4 -16  -6   0 -15  -3   5  -1]\n",
      "   [ -2   7  -1 -15   0  23 -10 -13]]]]\n",
      "reference:  [[[  270  -258   111  -462  -300   211   365  -162]\n",
      "  [  540  -453  -644   939   634  -415   -57   725]\n",
      "  [  547  -745   147  -136   118  -563   529   178]\n",
      "  [ -364   268   -83   285   376    18    47   848]]\n",
      "\n",
      " [[  588   871    44  -305 -1182   -50   343  -165]\n",
      "  [ -602   539   -78  -667  -264  -540  -376  -505]\n",
      "  [  497  -101   177   226   565  -641   -24   721]\n",
      "  [ -197   384  -373   452    25  -376  -700  -232]]\n",
      "\n",
      " [[ -265   125  -379  -373  -710  -335   478     4]\n",
      "  [ -883  -219   167  -310  -752  -168  -243    -3]\n",
      "  [  687  -412  -286   260  -100    58   -83   123]\n",
      "  [   53    45   204   302   366  -102   -85  -349]]\n",
      "\n",
      " [[   60  -397   448    48   -40   298   505   141]\n",
      "  [ -454   471   601    62   490   115   -50   689]\n",
      "  [  -78  -249   744    43   213     8  -261   102]\n",
      "  [   82  -186  -289   -63   419  -147   310   332]]]\n",
      "reference winograd:  [[[  267  -261   107  -465  -303   207   361  -164]\n",
      "  [  542  -452  -645   940   634  -415   -56   727]\n",
      "  [  544  -746   142  -139   115  -565   527   176]\n",
      "  [ -363   268   -83   285   376    18    47   847]]\n",
      "\n",
      " [[  589   872    44  -305 -1183   -50   344  -164]\n",
      "  [ -602   539   -78  -667  -264  -539  -376  -505]\n",
      "  [  499  -100   177   228   566  -642   -23   721]\n",
      "  [ -197   383  -373   452    25  -376  -701  -232]]\n",
      "\n",
      " [[ -267   124  -381  -376  -712  -339   474     2]\n",
      "  [ -883  -218   168  -308  -753  -168  -243    -2]\n",
      "  [  684  -412  -288   257  -103    57   -87   122]\n",
      "  [   52    46   205   303   366  -102   -85  -349]]\n",
      "\n",
      " [[   60  -396   448    49   -39   299   505   141]\n",
      "  [ -453   471   601    62   490   115   -50   689]\n",
      "  [  -78  -248   745    44   215     9  -261   101]\n",
      "  [   82  -186  -290   -64   419  -148   310   332]]]\n",
      "Num PEs:  32\n",
      "image size:  (4, 4)\n",
      "filter size:  (3, 3)\n",
      "input channels:  4\n",
      "output channels:  8\n",
      "/tb: \n",
      "\tpe_comp_energy: 4096\n",
      "\tdram_mem_acc: 1280\n",
      "\tglb_mem_acc: 512\n",
      "\trf_mem_acc: 2048\n",
      "\ttotal_mem_acc: 3840\n",
      "\ttotal_noc_multicasts: 1280\n",
      "\tdram_energy: 256000\n",
      "\tglb_energy: 3072\n",
      "\trf_energy: 2048\n",
      "\tdata_energy: 261120\n",
      "\tcomp_energy: 4096\n",
      "\ttotal_energy: 265216\n",
      "/tb/chip: \n",
      "\tdram_rd: 768\n",
      "\tdram_wr: 512\n",
      "\tpe_mac: 2048\n",
      "\tpe_chn_pop: 1536\n",
      "\tpe_chn_push: 2048\n",
      "\tpe_rf_rd: 1536\n",
      "\tpe_rf_wr: 512\n",
      "/tb/chip/ifmap_glb: \n",
      "\tsize: (64, 4)\n",
      "\tifmap_glb_rd: 256\n",
      "\tifmap_glb_wr: 256\n",
      "/tb/chip/weight_glb: \n",
      "\tsize: (0, 0)\n",
      "\tweight_glb_rd: 0\n",
      "\tweight_glb_wr: 0\n",
      "/tb/chip/weight_noc: \n",
      "\tnoc_multicast: 512\n",
      "/tb/chip/ifmap_noc: \n",
      "\tnoc_multicast: 256\n",
      "/tb/chip/psum_wr_noc: \n",
      "\tnoc_multicast: 512\n",
      "\n",
      "cyc 208: Success\n"
     ]
    }
   ],
   "source": [
    "from ws_2d_winograd_off.tb import WSArchTB\n",
    "\n",
    "ws_tb = WSArchTB()\n",
    "run_tb(ws_tb, verbose=False, dump_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winograd Transform - Move Post Processing On Chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifmap glb depth: 64\n",
      "weight glb depth: 0\n",
      "ifmaps:  [[[  3   4  -3  -6]\n",
      "  [ -8 -19   2 -13]\n",
      "  [  3 -10  -1   5]\n",
      "  [ -8  18   3 -10]]\n",
      "\n",
      " [[  5   4 -15  -8]\n",
      "  [  0  -3  24  -5]\n",
      "  [-19   7   3   5]\n",
      "  [ -6  -3   0   1]]\n",
      "\n",
      " [[ 13  -5 -13  -2]\n",
      "  [ 10  -2 -17   3]\n",
      "  [ -6  -3  -5  -5]\n",
      "  [-15  -8  -8   2]]\n",
      "\n",
      " [[ 20 -17   0  -6]\n",
      "  [ -8   2   4  -8]\n",
      "  [ -8  15  12  -9]\n",
      "  [  3  15   7  16]]]\n",
      "weights:  [[[[ -9   2  10  13  11   0  10  -2]\n",
      "   [-13 -11  -5   3  -5  -7   0   0]\n",
      "   [  3  14  -1 -13   0   9  15  -7]\n",
      "   [ -6  10  -3   7 -11 -10   2  -9]]\n",
      "\n",
      "  [[ 10   0  -1  -9  -3   8  -1  -3]\n",
      "   [ -2   9 -14   7 -17  -2   3   5]\n",
      "   [ -6  11   4  14   0   4  15   3]\n",
      "   [ -2   7   5   0  -7  -3 -16 -15]]\n",
      "\n",
      "  [[  7 -25   2   0  14  -2   0 -14]\n",
      "   [  0 -24  -2  -1   2   5 -10  -2]\n",
      "   [ -5  -1  -4  16  12  -4  -7  -5]\n",
      "   [-12   4  -4  -6   2 -11   2 -21]]]\n",
      "\n",
      "\n",
      " [[[ -1  14  21  -3   6  11   5 -13]\n",
      "   [  8   0 -26   5  14  24   4   0]\n",
      "   [ -3  12  -3   1  -1   1   7   0]\n",
      "   [  0  -5 -11   5   0 -11  -9  -7]]\n",
      "\n",
      "  [[ -6   2 -16  -5   7   8  12   1]\n",
      "   [ -3   6   8  -4  -1  13   0   2]\n",
      "   [  2 -10   3  11   1   3  -3   5]\n",
      "   [-16  -4 -11   0   4   8 -15  10]]\n",
      "\n",
      "  [[ -7  -1   1 -12   1   3  15   4]\n",
      "   [  4   0   0  -6  -3  -7   6  -5]\n",
      "   [  3   7  10 -17   2   3  12   0]\n",
      "   [ -4 -14  18  -1  10 -13   1   3]]]\n",
      "\n",
      "\n",
      " [[[ -8  10   1  10   0 -10  -3  -2]\n",
      "   [  7  19  -6   4   2  -5 -11   1]\n",
      "   [  8   5   2  10   3 -13 -18   2]\n",
      "   [  1  -6  -3  -3 -21  18  12  -6]]\n",
      "\n",
      "  [[-24  -3   8   1   1 -28  13   9]\n",
      "   [ -2   8   1  -9  11  14 -12 -11]\n",
      "   [-14   6   0  15   2  -9   0 -11]\n",
      "   [ -2   6  22   2  21  -5   9  -3]]\n",
      "\n",
      "  [[-10 -14  -8  14  -4   8  22   3]\n",
      "   [  8   8 -19   0  -1  -5  -7   2]\n",
      "   [  1   8   2   4  11 -10  14   8]\n",
      "   [-14 -18  -2   1  12  14  21  12]]]]\n",
      "biases:  [  5  10 -19   2 -13 -11  18   8]\n",
      "reference orig conv:  [[[  271   435  -217   -54   -42    88   127   284]\n",
      "  [   -5   313   100   222   261  -616   -61  -241]\n",
      "  [  540   388   249   -38   -56  -318  -824  -154]\n",
      "  [  463    45   544  -156  -345   152   -61  -126]]\n",
      "\n",
      " [[   -8   512    64  -567  -508   203   988   618]\n",
      "  [  102  -560   849    -7   570  -232   227   165]\n",
      "  [  505   -42   624  -515  -235   893  -722   224]\n",
      "  [  522  -169  -886   295  -244   190   132   511]]\n",
      "\n",
      " [[ -327  -112  -560   239     4 -1127    50   357]\n",
      "  [ -339   874  -140   503     8  -211  -345    70]\n",
      "  [   28   612  -294   309   288   272  -184  -253]\n",
      "  [   95   410   287   -71   353  -778  -816  -124]]\n",
      "\n",
      " [[  481  -255  -446  -628    32    31   234  -319]\n",
      "  [  379   428  1276  -366  -323  -182  -112  -241]\n",
      "  [  -52    98   712    48  -127  -363   317   504]\n",
      "  [ -190  -196  -517   -20   385   624  -328   446]]]\n",
      "reference winograd:  [[[  269   433  -219   -57   -43    86   124   284]\n",
      "  [   -5   313   101   223   261  -615   -60  -240]\n",
      "  [  538   386   248   -41   -58  -322  -825  -156]\n",
      "  [  463    45   545  -155  -345   153   -60  -124]]\n",
      "\n",
      " [[   -8   513    63  -566  -507   204   988   619]\n",
      "  [  102  -560   849    -7   570  -232   227   165]\n",
      "  [  505   -42   625  -515  -235   893  -722   225]\n",
      "  [  521  -170  -886   296  -245   190   133   511]]\n",
      "\n",
      " [[ -330  -114  -564   237     2 -1130    49   353]\n",
      "  [ -340   875  -139   503     9  -210  -344    71]\n",
      "  [   24   608  -296   305   286   270  -187  -256]\n",
      "  [   96   409   287   -70   354  -777  -815  -123]]\n",
      "\n",
      " [[  481  -255  -446  -628    34    31   234  -318]\n",
      "  [  379   428  1276  -367  -323  -182  -112  -242]\n",
      "  [  -51    99   713    49  -126  -362   317   504]\n",
      "  [ -190  -196  -517   -19   386   623  -328   447]]]\n",
      "ifmap glb_size:  64\n",
      "Num PEs:  32\n",
      "Num post transform blocks:  32\n",
      "image size:  (4, 4)\n",
      "filter size:  (3, 3)\n",
      "input channels:  4\n",
      "output channels:  8\n",
      "/tb: \n",
      "\tpe_comp_energy: 4096\n",
      "\ttr_alu_comp_energy: 1792\n",
      "\tdram_mem_acc: 904\n",
      "\tglb_mem_acc: 512\n",
      "\trf_mem_acc: 4352\n",
      "\ttotal_mem_acc: 5768\n",
      "\ttotal_noc_multicasts: 1416\n",
      "\tdram_energy: 180800\n",
      "\tglb_energy: 3072\n",
      "\trf_energy: 4352\n",
      "\tdata_energy: 188224\n",
      "\tcomp_energy: 5888\n",
      "\ttotal_energy: 194112\n",
      "/tb/chip: \n",
      "\tdram_rd: 776\n",
      "\tdram_wr: 128\n",
      "\tpe_mac: 2048\n",
      "\tpe_chn_pop: 1536\n",
      "\tpe_chn_push: 2048\n",
      "\tpe_rf_rd: 1536\n",
      "\tpe_rf_wr: 512\n",
      "\tpost_tr_alu_comp: 1792\n",
      "\tpost_tr_rf_rd: 1152\n",
      "\tpost_tr_ifmap_rf_wr: 1152\n",
      "/tb/chip/ifmap_glb: \n",
      "\tsize: (64, 4)\n",
      "\tifmap_glb_rd: 256\n",
      "\tifmap_glb_wr: 256\n",
      "/tb/chip/weight_glb: \n",
      "\tsize: (0, 0)\n",
      "\tweight_glb_rd: 0\n",
      "\tweight_glb_wr: 0\n",
      "/tb/chip/bias_glb: \n",
      "\tsize: (0, 0)\n",
      "\tbias_glb_rd: 0\n",
      "\tbias_glb_wr: 0\n",
      "/tb/chip/weight_noc: \n",
      "\tnoc_multicast: 512\n",
      "/tb/chip/ifmap_noc: \n",
      "\tnoc_multicast: 256\n",
      "/tb/chip/bias_noc: \n",
      "\tnoc_multicast: 8\n",
      "/tb/chip/post_tr_wr_noc: \n",
      "\tnoc_multicast: 512\n",
      "/tb/chip/post_tr_rd_noc: \n",
      "\tnoc_multicast: 128\n",
      "\n",
      "cyc 213: Success\n"
     ]
    }
   ],
   "source": [
    "from ws_2d_winograd_post_on.tb import WSArchTB\n",
    "\n",
    "ws_tb = WSArchTB()\n",
    "run_tb(ws_tb, verbose=False, dump_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winograd Transform - Pre & Post Processing On Chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifmap glb depth: 64\n",
      "weight glb depth: 0\n",
      "ifmaps:  [[[-17  -1 -10   7]\n",
      "  [ -6  -6  -9  16]\n",
      "  [  5  16   7  12]\n",
      "  [  2 -13   1   7]]\n",
      "\n",
      " [[  2  32  -3   0]\n",
      "  [  4 -11   3   2]\n",
      "  [  4  -7  22 -15]\n",
      "  [ -5  -8 -14   6]]\n",
      "\n",
      " [[-12  -7   5   7]\n",
      "  [  7  18  -2 -10]\n",
      "  [ -9   5  -3  21]\n",
      "  [-15   7   3   2]]\n",
      "\n",
      " [[ -8 -22 -17   4]\n",
      "  [  7  24  -7  -2]\n",
      "  [  1  -5   5  -1]\n",
      "  [ 13   6 -14   0]]]\n",
      "weights:  [[[[  1  -3   1  -7  -5  -7  -6  10]\n",
      "   [ -7  -5   2  -3  -2 -10  -8  -5]\n",
      "   [-17 -16  13  -1  12   3  -2  -5]\n",
      "   [ 20  -5   9   1  -8   2  -9  -2]]\n",
      "\n",
      "  [[  3  -3  14   0   9 -15 -18 -10]\n",
      "   [-13  -6 -13  -3   1 -12   5   4]\n",
      "   [  5   4   4 -10 -15  -9  -6 -10]\n",
      "   [ -9  -7  13  13  11  14  -1  -7]]\n",
      "\n",
      "  [[ 12   2  -1  20  -7  -3 -10  -1]\n",
      "   [ -2   8  -7   0  -4  13  10   4]\n",
      "   [ -2  -9  17  14   0  12   0  -7]\n",
      "   [  2 -17   6  -3 -12   1   7   0]]]\n",
      "\n",
      "\n",
      " [[[  6   5 -15   9   4   8   3  -3]\n",
      "   [ -7  -7  -7   3   4  -2  -4  -4]\n",
      "   [ -2   3  -2   8  -4   2   0  13]\n",
      "   [  0   0  -9   0  -5  13 -11  -8]]\n",
      "\n",
      "  [[ 15  -1 -19   9   2   2 -14   0]\n",
      "   [ -1 -12   6   4   7   1  -8   0]\n",
      "   [ 16  11   8   0  -3  -6  10   6]\n",
      "   [ -1   4   2 -12  18   7  -3  -3]]\n",
      "\n",
      "  [[-14   0   4  23  10  -2  -6   3]\n",
      "   [ 17 -19  -1   2  -5   3   9  -9]\n",
      "   [ -1  19  -5   4  -1  13  13  -7]\n",
      "   [ -5   7  -7  -3  -4 -25 -27  -7]]]\n",
      "\n",
      "\n",
      " [[[ 13   4   5   4   0  -8   7   3]\n",
      "   [  2  -6  -1  -4   1  -2  15  21]\n",
      "   [ 11 -25   5 -16  -1  -5   8  -3]\n",
      "   [-22   4   6  -7   4   0  11   5]]\n",
      "\n",
      "  [[  8  15  10  -5   5   0  -4   5]\n",
      "   [  1  -3 -10   7   9 -18   2   9]\n",
      "   [ 28  -1   3  -1  24  -4   8  -2]\n",
      "   [ 10 -11   3  -9   0   1 -28   4]]\n",
      "\n",
      "  [[-19 -28  -9  15  -1  -6  25  -6]\n",
      "   [-17  15  12  29   0   7  13  -5]\n",
      "   [ -5  10  15  -6  -2  -7  18   7]\n",
      "   [  0   8   6   1   4   5   9   3]]]]\n",
      "biases:  [  9 -15   1   6   9 -10  -7 -11]\n",
      "reference orig conv:  [[[ -441  -307  -253  -527   263 -1135  -388   257]\n",
      "  [  -60  -325   391  -841    38  -275   414   224]\n",
      "  [  718   380    19  -345   826   107  -598  -516]\n",
      "  [  195  -543  -349  -237  -481   280  -465  -431]]\n",
      "\n",
      " [[ -780  -704    -5   700   231   456   168    28]\n",
      "  [ -243   860   -99   975   411  1404  1083  -182]\n",
      "  [ 1296   121   378    86  -665  -728  -886   643]\n",
      "  [ -739  -327   412    38   218    -1    41   271]]\n",
      "\n",
      " [[-1216  -640   276   763  -491   371   699  -395]\n",
      "  [ -399   184   240   552  -201  -966 -1872  -664]\n",
      "  [  410  -343  -294  -760    44  -410   547   -34]\n",
      "  [-1118  -325   527   -75   316   532   -47   -63]]\n",
      "\n",
      " [[   11  -122  -247   189  -187   595   420  -185]\n",
      "  [  -90  -568    92  -391     8   -56    28  -150]\n",
      "  [ -845  -665  -109   254   457    43   139   -62]\n",
      "  [  293  -253  -415   228  -232   309  -227   -13]]]\n",
      "reference winograd:  [[[ -443  -309  -255  -529   259 -1136  -391   255]\n",
      "  [  -59  -325   391  -842    38  -275   414   224]\n",
      "  [  716   378    16  -348   822   105  -600  -518]\n",
      "  [  195  -543  -349  -237  -481   281  -464  -430]]\n",
      "\n",
      " [[ -780  -705    -6   700   231   456   169    27]\n",
      "  [ -243   860   -99   975   410  1404  1083  -182]\n",
      "  [ 1297   122   379    86  -665  -728  -887   644]\n",
      "  [ -739  -326   412    38   218    -1    41   272]]\n",
      "\n",
      " [[-1219  -642   275   760  -494   370   696  -397]\n",
      "  [ -398   184   241   551  -200  -966 -1871  -663]\n",
      "  [  409  -346  -295  -762    41  -413   544   -37]\n",
      "  [-1118  -324   527   -74   315   532   -48   -64]]\n",
      "\n",
      " [[   11  -122  -247   189  -186   596   420  -184]\n",
      "  [  -90  -567    92  -391     7   -56    27  -150]\n",
      "  [ -844  -664  -108   255   457    42   139   -62]\n",
      "  [  293  -253  -415   228  -232   309  -227   -13]]]\n",
      "diff b/w orig conv and winograd conv:  [[[ 2  2  2  2  4  1  3  2]\n",
      "  [-1  0  0  1  0  0  0  0]\n",
      "  [ 2  2  3  3  4  2  2  2]\n",
      "  [ 0  0  0  0  0 -1 -1 -1]]\n",
      "\n",
      " [[ 0  1  1  0  0  0 -1  1]\n",
      "  [ 0  0  0  0  1  0  0  0]\n",
      "  [-1 -1 -1  0  0  0  1 -1]\n",
      "  [ 0 -1  0  0  0  0  0 -1]]\n",
      "\n",
      " [[ 3  2  1  3  3  1  3  2]\n",
      "  [-1  0 -1  1 -1  0 -1 -1]\n",
      "  [ 1  3  1  2  3  3  3  3]\n",
      "  [ 0 -1  0 -1  1  0  1  1]]\n",
      "\n",
      " [[ 0  0  0  0 -1 -1  0 -1]\n",
      "  [ 0 -1  0  0  1  0  1  0]\n",
      "  [-1 -1 -1 -1  0  1  0  0]\n",
      "  [ 0  0  0  0  0  0  0  0]]]\n",
      "ifmap glb_size:  64\n",
      "Num PEs:  32\n",
      "Num pre transform ifmap blocks:  16\n",
      "Num pre transform weights blocks:  32\n",
      "Num post transform blocks:  32\n",
      "image size:  (4, 4)\n",
      "filter size:  (3, 3)\n",
      "input channels:  4\n",
      "output channels:  8\n",
      "/tb: \n",
      "\tpe_comp_energy: 4096\n",
      "\ttr_alu_comp_energy: 5376\n",
      "\tdram_mem_acc: 488\n",
      "\tglb_mem_acc: 512\n",
      "\trf_mem_acc: 11808\n",
      "\ttotal_mem_acc: 12808\n",
      "\ttotal_noc_multicasts: 2536\n",
      "\tdram_energy: 97600\n",
      "\tglb_energy: 3072\n",
      "\trf_energy: 11808\n",
      "\tdata_energy: 112480\n",
      "\tcomp_energy: 9472\n",
      "\ttotal_energy: 121952\n",
      "/tb/chip: \n",
      "\tdram_rd: 360\n",
      "\tdram_wr: 128\n",
      "\tpe_mac: 2048\n",
      "\tpe_chn_pop: 1536\n",
      "\tpe_chn_push: 2048\n",
      "\tpe_rf_rd: 1536\n",
      "\tpe_rf_wr: 512\n",
      "\tpre_tr_ifmap_alu_comp: 1024\n",
      "\tpre_tr_ifmap_rf_rd: 1216\n",
      "\tpre_tr_ifmap_rf_wr: 1312\n",
      "\tpre_tr_weights_alu_comp: 2560\n",
      "\tpre_tr_weights_rf_rd: 2720\n",
      "\tpre_tr_weights_rf_wr: 2208\n",
      "\tpost_tr_alu_comp: 1792\n",
      "\tpost_tr_rf_rd: 1152\n",
      "\tpost_tr_rf_wr: 1152\n",
      "/tb/chip/ifmap_glb: \n",
      "\tsize: (64, 4)\n",
      "\tifmap_glb_rd: 256\n",
      "\tifmap_glb_wr: 256\n",
      "/tb/chip/weight_glb: \n",
      "\tsize: (0, 0)\n",
      "\tweight_glb_rd: 0\n",
      "\tweight_glb_wr: 0\n",
      "/tb/chip/bias_glb: \n",
      "\tsize: (0, 0)\n",
      "\tbias_glb_rd: 0\n",
      "\tbias_glb_wr: 0\n",
      "/tb/chip/weight_noc: \n",
      "\tnoc_multicast: 512\n",
      "/tb/chip/ifmap_noc: \n",
      "\tnoc_multicast: 256\n",
      "/tb/chip/bias_noc: \n",
      "\tnoc_multicast: 8\n",
      "/tb/chip/post_tr_wr_noc: \n",
      "\tnoc_multicast: 512\n",
      "/tb/chip/post_tr_rd_noc: \n",
      "\tnoc_multicast: 128\n",
      "/tb/chip/ifmap_tiler: \n",
      "\tnoc_multicast: 64\n",
      "/tb/chip/pre_tr_ifmap_rd_noc: \n",
      "\tnoc_multicast: 256\n",
      "/tb/chip/pre_tr_weights_wr_noc: \n",
      "\tnoc_multicast: 288\n",
      "/tb/chip/pre_tr_weights_rd_noc: \n",
      "\tnoc_multicast: 512\n",
      "\n",
      "cyc 193: Success\n"
     ]
    }
   ],
   "source": [
    "from ws_2d_winograd_on_chip.tb import WSArchTB\n",
    "\n",
    "ws_tb = WSArchTB()\n",
    "run_tb(ws_tb, verbose=False, dump_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
