{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.888 Final Project - Winograd Transforms\n",
    "\n",
    "### Madeleine Waller & Diana Wofk\n",
    "\n",
    "In this project, we use as our baseline this course's lab 4 WS 2D Architecture.  We build on this architecture in the following steps: <br />\n",
    "- Include the baseline architecture with added energy computations for performance comparison.\n",
    "- Redesign the PE array to perform element wise multiplications of the transformed weights/ifmaps (rather than convolution). Implement off chip pre/post processing of ifmaps, weights, and ofmaps.\n",
    "- Move the post processing (reverse transform of ofmaps) onto the chip via a specialized adder array, similar to the PE array.\n",
    "- Move the pre processing on chip (in addition to the post processing), using a similar specialized adder array to transform both the weights and ifmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nnsim.simulator import run_tb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline WS 2D Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifmap glb depth: 16\n",
      "psum glb depth: 32\n",
      "weight glb depth: 0\n",
      "ifmap:  [[[ 17   4   9  22]\n",
      "  [ 18  -9   9  -1]\n",
      "  [ -1   4   1  14]\n",
      "  [  7   1   4   3]]\n",
      "\n",
      " [[ 14  -2   3  -8]\n",
      "  [-25   6   8  -7]\n",
      "  [ 22 -14   0  -1]\n",
      "  [ 15  14   1   3]]\n",
      "\n",
      " [[ -8 -19  -3   1]\n",
      "  [ 12  12  -3  -3]\n",
      "  [-10 -14 -17  19]\n",
      "  [ -5  -4 -12   7]]\n",
      "\n",
      " [[-16  -2  -8   3]\n",
      "  [ -5 -11   0   4]\n",
      "  [  0   3  -6  -3]\n",
      "  [ -6  -3  -8 -17]]]\n",
      "weights:  [[[[  1  -4 -16   4  -9   0   7   1]\n",
      "   [ 11 -12   4  -6  -8  -5  -3   0]\n",
      "   [-11   9   4 -15  14  18  11  -1]\n",
      "   [-10  10  -4  12   2   9   3   7]]\n",
      "\n",
      "  [[  0  17   1   4  18 -13 -12   9]\n",
      "   [-11  19  -4  -7  19  14  18   9]\n",
      "   [ -8  19  -2   8   9  -1   6   9]\n",
      "   [  3 -10   2  13  -6  -1  -4  18]]\n",
      "\n",
      "  [[  6   4  -7   5  -6   0  -6   6]\n",
      "   [  5  -2   3 -10 -14   4   1   6]\n",
      "   [ 23   9  -9  11 -13  -4   0  17]\n",
      "   [ -7  -8   0  -6  11 -10 -11  -4]]]\n",
      "\n",
      "\n",
      " [[[ -4  19   9   0 -12   8 -10 -15]\n",
      "   [ 11   3   9   3   8  -6 -10   6]\n",
      "   [ -8  -6  -4   0  -3 -13  -6 -22]\n",
      "   [  6 -16 -11   0  -7  15 -12   2]]\n",
      "\n",
      "  [[  0 -11   5  -1   7   8  21  13]\n",
      "   [ -3  -2  10   6   6 -16   0  -7]\n",
      "   [  2   0   9   3   7  -4  -9  -4]\n",
      "   [  0   3  22   0  -9  -3  -4   4]]\n",
      "\n",
      "  [[-15   0   1   2  -5  -2 -14  -4]\n",
      "   [ -5   4 -11   7  14 -20   4   6]\n",
      "   [ -6  -3  -1  -2  -3 -16  11  10]\n",
      "   [ -8 -14   5  -5   1  -3   6   6]]]\n",
      "\n",
      "\n",
      " [[[ -7 -13 -15   6 -11  -5  -5   0]\n",
      "   [-19   1   5   0  -3   0   3 -27]\n",
      "   [ 19   3  -6  -3   4  -1 -20  20]\n",
      "   [ -1  10  -6  15   2   6 -10  12]]\n",
      "\n",
      "  [[  6  13  -6  -4  23 -10  -1  11]\n",
      "   [  0   5  -3   3 -13  16  -1  -6]\n",
      "   [  6  -4 -13 -13   6  -1  -1  10]\n",
      "   [-11  -7  -3   0   0  -2   0  -1]]\n",
      "\n",
      "  [[ -7  -8   2  -8 -11  -3  -1  22]\n",
      "   [ -7   9   7 -11   7 -11 -26   6]\n",
      "   [-17   4  -6  16  10  -4  -6 -12]\n",
      "   [ -4  -2  -3   1   5   3  -7 -14]]]]\n",
      "bias:  [ 13  -6  -6  -5 -18  -4  -4   6]\n",
      "(4, 4, 4) (3, 3, 4, 8) (8,)\n",
      "reference:  [[[  -37   332   659   143   474  -234  -156   -99]\n",
      "  [ -101 -1276  -204  -138 -1257   756   198   208]\n",
      "  [ -273   778   834  -670   463  -724  -615   130]\n",
      "  [  318  -383  -538   104   -52   127  -281   585]]\n",
      "\n",
      " [[  423   225  -170   407   512  -671   188  1618]\n",
      "  [  141  1133  -158   258     8   176  -822  -486]\n",
      "  [ -770 -1028  -471   360   103  -263  1011   330]\n",
      "  [ -602   660   593   682   -49   329   381    61]]\n",
      "\n",
      " [[ -128   301  -154   271  -322   173    48  -411]\n",
      "  [  -35  -626     9  -348  -109   848  1235   -97]\n",
      "  [ 1062   783  1044  -329  -422   163  -900   593]\n",
      "  [ -203   237  -554   159   -45   657   520   514]]\n",
      "\n",
      " [[  421  -460    79  -117 -1122    71  -525  -313]\n",
      "  [ -750   176   -77  -195  1386    88  -131    12]\n",
      "  [  383 -1337  -229    25  -722    71  -299  -481]\n",
      "  [   63  -106  -419   498  -232    43  -218   134]]]\n",
      "image size: (4, 4)\n",
      "filter size: (3, 3)\n",
      "in chn: 4\n",
      "out chn: 8\n",
      "PE array size: 32\n",
      "/tb: \n",
      "\tpe_comp_energy: 9216\n",
      "\tdram_memory_acc: 608\n",
      "\tglb_memory_acc: 2752\n",
      "\trf_memory_acc: 4320\n",
      "\tinter_pe_acc: 3456\n",
      "\ttotal_memory_acc: 11136\n",
      "\tdram_energy: 121600\n",
      "\tglb_energy: 16512\n",
      "\trf_energy: 4320\n",
      "\tinter_pe_energy: 6912\n",
      "\tdata_energy: 149344\n",
      "\tcomp_energy: 9216\n",
      "\ttotal_energy: 158560\n",
      "/tb/chip: \n",
      "\tdram_rd: 480\n",
      "\tdram_to_glb_acc: 192\n",
      "\tdram_to_pe_acc: 288\n",
      "\tdram_wr: 128\n",
      "\tpe_mac: 4608\n",
      "\tpe_to_pe_acc: 3456\n",
      "\trf_to_pe_acc: 4320\n",
      "\tpe_out_psum: 1152\n",
      "/tb/chip/ifmap_glb: \n",
      "\tsize: (16, 4)\n",
      "\trd: 576\n",
      "\twr: 64\n",
      "\tglb_to_pe_acc: 576\n",
      "/tb/chip/psum_glb: \n",
      "\tsize: (32, 4)\n",
      "\trd: 1152\n",
      "\twr: 1152\n",
      "\tglb_to_pe_acc: 1152\n",
      "/tb/chip/weight_glb: \n",
      "\tsize: (0, 0)\n",
      "\trd: 288\n",
      "\twr: 288\n",
      "/tb/chip/weight_noc: \n",
      "\tnoc_multicast: 288\n",
      "/tb/chip/ifmap_noc: \n",
      "\tnoc_multicast: 576\n",
      "/tb/chip/psum_rd_noc: \n",
      "\tnoc_multicast: 1152\n",
      "/tb/chip/psum_wr_noc: \n",
      "\tnoc_multicast: 1152\n",
      "\tpe_to_glb_acc: 1024\n",
      "\tpe_to_dram_acc: 128\n",
      "\n",
      "cyc 351: Success\n"
     ]
    }
   ],
   "source": [
    "from ws_2d.tb import WSArchTB\n",
    "\n",
    "ws_tb = WSArchTB()\n",
    "run_tb(ws_tb, verbose=False, dump_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winograd Transform - Pre/Post Processing Off Chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifmap glb depth: 64\n",
      "weight glb depth: 0\n",
      "ifmaps:  [[[ -4  -3   5  -9]\n",
      "  [ -4  -8 -10  -8]\n",
      "  [  6   0  -8  -2]\n",
      "  [-16  -7  21   0]]\n",
      "\n",
      " [[  7   0   3   6]\n",
      "  [-11   0  15  -7]\n",
      "  [ -5  -3   2   5]\n",
      "  [ 12   4   0  12]]\n",
      "\n",
      " [[  7 -14  25  17]\n",
      "  [ -1   3  13  -1]\n",
      "  [  7  11 -10  -6]\n",
      "  [  9   4   9  -1]]\n",
      "\n",
      " [[ -2 -19 -11   0]\n",
      "  [  8   5  -1  -2]\n",
      "  [  2   0  14   1]\n",
      "  [-14 -12  15 -11]]]\n",
      "weights:  [[[[  7  -2  -1  -1  12  -1   0 -15]\n",
      "   [  2   5   2  13   0   2  16 -15]\n",
      "   [ -4  14   9   6   8   3  16   3]\n",
      "   [  2   1   1 -11   7  -1  18   0]]\n",
      "\n",
      "  [[  4   2  -6   9  19   0  -3  -3]\n",
      "   [-18  -1   2  10   9  -4  -2  11]\n",
      "   [ -1  -5  13  10   0  -5 -20   5]\n",
      "   [ -8 -19  15   6 -11 -12   8  -8]]\n",
      "\n",
      "  [[ 12   6   5   4   1   8  -4   0]\n",
      "   [  7   5 -11  -5   2  -4  17  -3]\n",
      "   [ -1   7   3  -1  -7   3  10   4]\n",
      "   [ -7  17 -14 -15   9   2  -5 -10]]]\n",
      "\n",
      "\n",
      " [[[ 23   1   5   3   4   5   7  -3]\n",
      "   [ -2 -17  -7   2  10   5  -3 -12]\n",
      "   [-27  11  -5  -4   1 -14  -3  20]\n",
      "   [  5   3 -15  22 -14  19 -21  14]]\n",
      "\n",
      "  [[ 16  -8   4   5  -8 -14 -13   5]\n",
      "   [  0  -5   9   5  -7 -12   5  -5]\n",
      "   [  0  15   5  -8   1  -9  16  -5]\n",
      "   [  2   3   1 -19 -14  -4   3  -1]]\n",
      "\n",
      "  [[ -9 -13  -4  -4   5  -3   6  -5]\n",
      "   [ -2  -3  -7   6  -8  -5   0 -12]\n",
      "   [ -3  -7  -3   0  -7  -2  13   0]\n",
      "   [ 11   3   7  -7   1   1  -6  -8]]]\n",
      "\n",
      "\n",
      " [[[-14  14  -9  13  -4  -8   6  -6]\n",
      "   [  5  -3   4  -9   8   4  -9  26]\n",
      "   [  5  22  16  -1  -4  -4 -18  -6]\n",
      "   [  2  15  -7   8 -12  -5  -4   3]]\n",
      "\n",
      "  [[  4   9   7   2   3  15  -5   7]\n",
      "   [-18   4  -4   0  10   1   8  14]\n",
      "   [  3  11  -3   0  -5  10   4  -5]\n",
      "   [  1  10   0  -9   1 -19   7  -4]]\n",
      "\n",
      "  [[ -4   8 -13  19  -4  -5  10   7]\n",
      "   [ 24  -2  -1 -14  -3  -7  -4 -17]\n",
      "   [ 16 -14 -28 -11  -6 -11  10  -1]\n",
      "   [  0   6   2   9 -11  -5   6 -25]]]]\n",
      "reference:  [[[ 226   38 -236 -348  341   82    5  264]\n",
      "  [-508  168 -210   82  102    2  -27 -179]\n",
      "  [ 636  157  457   10 -359 -284   75 -392]\n",
      "  [ 138  697  172 -352  266  163  618 -297]]\n",
      "\n",
      " [[ 811  150 -233 -269 -621 -251  -10 -109]\n",
      "  [ 278 1851  116  337 -359  262 -200 -430]\n",
      "  [-904  149 -377 -643  -43 -456 -159  522]\n",
      "  [  61 -307  161 -113 -582  -47 -592  527]]\n",
      "\n",
      " [[ 338    1  162 -274 -556 -630  511 -175]\n",
      "  [-594  487 -766  236 -380 -309  146  427]\n",
      "  [-533 -109 -325 -105  -63 -110  102  594]\n",
      "  [ 587 -211  452  206  -58 -246   59 -796]]\n",
      "\n",
      " [[ -24 -504  209  262 -124   39 -361  -65]\n",
      "  [ 456  131  542   97  107 -222  467  306]\n",
      "  [ 163  673   58  131  339  139  942  262]\n",
      "  [-524  411 -204  287  561   13  -31   -4]]]\n",
      "reference winograd:  [[[ 223   33 -237 -351  339   78    2  263]\n",
      "  [-509  168 -211   81  101    2  -26 -179]\n",
      "  [ 632  155  453    8 -362 -285   73 -395]\n",
      "  [ 138  698  172 -351  266  162  617 -296]]\n",
      "\n",
      " [[ 812  150 -233 -269 -620 -251   -9 -108]\n",
      "  [ 278 1851  116  337 -359  262 -200 -430]\n",
      "  [-903  150 -376 -644  -43 -455 -158  523]\n",
      "  [  61 -308  162 -113 -581  -47 -592  527]]\n",
      "\n",
      " [[ 335   -2  159 -275 -560 -634  509 -178]\n",
      "  [-595  486 -766  236 -379 -309  147  428]\n",
      "  [-537 -111 -329 -108  -67 -113   99  591]\n",
      "  [ 587 -211  452  208  -59 -246   58 -795]]\n",
      "\n",
      " [[ -23 -503  210  263 -123   39 -360  -64]\n",
      "  [ 456  131  542   96  107 -222  467  306]\n",
      "  [ 163  674   59  132  339  139  942  264]\n",
      "  [-524  411 -204  287  561   14  -31   -4]]]\n",
      "Num PEs:  32\n",
      "image size:  (4, 4)\n",
      "filter size:  (3, 3)\n",
      "input channels:  4\n",
      "output channels:  8\n",
      "/tb: \n",
      "\tpe_comp_energy: 4096\n",
      "\tdram_memory_acc: 1280\n",
      "\tglb_memory_acc: 256\n",
      "\trf_memory_acc: 1536\n",
      "\tinter_pe_acc: 1536\n",
      "\ttotal_memory_acc: 4608\n",
      "\tdram_energy: 256000\n",
      "\tglb_energy: 1536\n",
      "\trf_energy: 1536\n",
      "\tinter_pe_energy: 3072\n",
      "\tdata_energy: 262144\n",
      "\tcomp_energy: 4096\n",
      "\ttotal_energy: 266240\n",
      "/tb/chip: \n",
      "\tdram_rd: 768\n",
      "\tdram_to_glb_acc: 256\n",
      "\tdram_to_pe_acc: 512\n",
      "\tdram_wr: 512\n",
      "\tpe_mac: 2048\n",
      "\tpe_to_pe_acc: 1536\n",
      "\trf_to_pe_acc: 1536\n",
      "\tpe_to_dram_acc: 512\n",
      "/tb/chip/ifmap_glb: \n",
      "\tsize: (64, 4)\n",
      "\trd: 256\n",
      "\twr: 256\n",
      "\tglb_to_pe_acc: 256\n",
      "/tb/chip/weight_glb: \n",
      "\tsize: (0, 0)\n",
      "\trd: 512\n",
      "\twr: 512\n",
      "/tb/chip/weight_noc: \n",
      "\tnoc_multicast: 512\n",
      "/tb/chip/ifmap_noc: \n",
      "\tnoc_multicast: 256\n",
      "/tb/chip/psum_wr_noc: \n",
      "\tnoc_multicast: 512\n",
      "\n",
      "cyc 208: Success\n"
     ]
    }
   ],
   "source": [
    "from ws_2d_winograd_off.tb import WSArchTB\n",
    "\n",
    "ws_tb = WSArchTB()\n",
    "run_tb(ws_tb, verbose=False, dump_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winograd Transform - Move Post Processing On Chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifmap glb depth: 64\n",
      "weight glb depth: 0\n",
      "ifmaps:  [[[ -3  -5   1  -3]\n",
      "  [-16  -8  -9  12]\n",
      "  [  8   5  -5  -8]\n",
      "  [ -5 -10  24 -22]]\n",
      "\n",
      " [[  5 -12  -1  -9]\n",
      "  [-11 -11  17  -1]\n",
      "  [ -7   5   0   7]\n",
      "  [-18   3   7 -16]]\n",
      "\n",
      " [[  4  16   0   8]\n",
      "  [  6  -7   0 -15]\n",
      "  [ -4   2   7   0]\n",
      "  [  7 -11  -1   0]]\n",
      "\n",
      " [[ 18  -2  -4   0]\n",
      "  [ -9   1  -3 -17]\n",
      "  [  0  -3 -16   0]\n",
      "  [ 14   5   6 -13]]]\n",
      "weights:  [[[[  4   1   5   4 -13   0  -7   0]\n",
      "   [ -8  13  -8  -8   0 -10  -4  -8]\n",
      "   [ 14   7   0  -3   9   4   4   0]\n",
      "   [-16  -1  -5   6  10  -6   4  17]]\n",
      "\n",
      "  [[ -6  16  -8   0   0   0  -8  -5]\n",
      "   [ -6   3   3  22  13  -5   3   9]\n",
      "   [  0   0   0   8  -8  -3   4   3]\n",
      "   [  2  -3   9  21   4  -1   7  -5]]\n",
      "\n",
      "  [[ -7   0 -25 -11  -3 -13 -10  -4]\n",
      "   [-16  -4  -5   0  11   1   0   0]\n",
      "   [  2 -10  -1   3 -13   8  10  -6]\n",
      "   [ -2  -8   6 -10  -2  -8   0 -17]]]\n",
      "\n",
      "\n",
      " [[[ 13  -9   0  -2  -7  -8   9  -5]\n",
      "   [  2  -8  -6   4   9  -1 -14  19]\n",
      "   [ -8 -15  25  -4 -14  -6   3   1]\n",
      "   [ -8  18  -5 -11   9  13  -8 -14]]\n",
      "\n",
      "  [[ 10 -20 -12   9   0  -2   3  -1]\n",
      "   [-12  12  13   2   0  23  -2  -2]\n",
      "   [  3  14  15  -2   3 -13  -3  -8]\n",
      "   [-10  16  -7  -5   3  12   4  27]]\n",
      "\n",
      "  [[  0   2   2  14   5  -1  -9   2]\n",
      "   [ 14  -4   5   2   8  -8  23 -12]\n",
      "   [ -3   9   2   8  -4   0   0  15]\n",
      "   [  6   7  -6   9   2  13  20  -3]]]\n",
      "\n",
      "\n",
      " [[[ -4  -8  -1  -3   3  -1  -3  10]\n",
      "   [ -9   4  -4   7  13  -3   4   1]\n",
      "   [ -7   2   2   4  -1   0 -11  -3]\n",
      "   [  5   8  -4   1   2   2   5 -18]]\n",
      "\n",
      "  [[  0   2 -10  16   1  15  -7  -9]\n",
      "   [  2 -16   2   0  10   7  -4 -10]\n",
      "   [ 17  -7 -10 -10  11  -5  -7   1]\n",
      "   [ -2  -6   7  10   9   7   4 -17]]\n",
      "\n",
      "  [[ 16   3   6  11  14   4   4  -5]\n",
      "   [  0  -8  -7  -8  -1  10  31   1]\n",
      "   [-13  12  -3  -6   2 -12   2   0]\n",
      "   [  0   3   0   0   2   4 -10 -14]]]]\n",
      "biases:  [  0 -14   0   9   6 -10  -8   3]\n",
      "reference orig conv:  [[[ -370   474  -322  -354  -402  -361  -179   105]\n",
      "  [    0     8   -71  -753  -156  -340   -54   687]\n",
      "  [ -871   231   -95  -334  -366    34  -742   153]\n",
      "  [  755  -136   292  -337     2 -1339   -35  -376]]\n",
      "\n",
      " [[  422  -543   431   158    28  -126  -217  -102]\n",
      "  [  185   301   -42  -181     2  -683   659  -101]\n",
      "  [ -481  -125   685  -189  -314   200  -130   995]\n",
      "  [ -166   626   187  -479  -610   -37  -573  -513]]\n",
      "\n",
      " [[ -284    88   125   -68  -730   867  -305   330]\n",
      "  [  819 -1101   280  -207  -450  -186  -178   259]\n",
      "  [  269    -8  1009  1022    71   384   922   900]\n",
      "  [  250  -625  -481  -251    21  -255    73   484]]\n",
      "\n",
      " [[  109  -386  -336   478   110  -313  -162   312]\n",
      "  [   73  -108  -209  -609  -282  -276  -111  -797]\n",
      "  [  464  -565   -52   403  -408  -207  -281   371]\n",
      "  [  440    56  -429   -53   162     8   -97  -646]]]\n",
      "reference winograd:  [[[ -373   472  -323  -355  -403  -362  -182   102]\n",
      "  [    1     8   -71  -753  -155  -340   -53   688]\n",
      "  [ -874   229   -98  -336  -368    31  -744   150]\n",
      "  [  756  -135   294  -336     3 -1338   -34  -376]]\n",
      "\n",
      " [[  422  -542   433   158    28  -126  -217  -101]\n",
      "  [  184   300   -42  -181     2  -684   659  -101]\n",
      "  [ -480  -124   686  -189  -314   202  -130   994]\n",
      "  [ -166   626   187  -479  -611   -37  -573  -513]]\n",
      "\n",
      " [[ -287    86   121   -69  -733   862  -308   327]\n",
      "  [  819 -1100   282  -206  -449  -185  -178   260]\n",
      "  [  265   -11  1005  1020    70   382   918   898]\n",
      "  [  250  -624  -480  -250    22  -254    73   484]]\n",
      "\n",
      " [[  108  -385  -336   478   111  -312  -162   313]\n",
      "  [   73  -107  -209  -608  -281  -276  -111  -797]\n",
      "  [  465  -563   -52   403  -408  -207  -280   371]\n",
      "  [  440    56  -429   -53   162     9   -98  -646]]]\n",
      "ifmap glb_size:  64\n",
      "Num PEs:  32\n",
      "Num post transform blocks:  32\n",
      "image size:  (4, 4)\n",
      "filter size:  (3, 3)\n",
      "input channels:  4\n",
      "output channels:  8\n",
      "/tb: \n",
      "\tpe_comp_energy: 4096\n",
      "\ttr_alu_comp_energy: 1792\n",
      "\tdram_mem_acc: 904\n",
      "\tglb_mem_acc: 512\n",
      "\trf_mem_acc: 4352\n",
      "\ttotal_mem_acc: 5768\n",
      "\ttotal_noc_multicasts: 1416\n",
      "\tdram_energy: 180800\n",
      "\tglb_energy: 3072\n",
      "\trf_energy: 4352\n",
      "\tdata_energy: 188224\n",
      "\tcomp_energy: 5888\n",
      "\ttotal_energy: 194112\n",
      "/tb/chip: \n",
      "\tdram_rd: 776\n",
      "\tdram_wr: 128\n",
      "\tpe_mac: 2048\n",
      "\tpe_chn_pop: 1536\n",
      "\tpe_chn_push: 2048\n",
      "\tpe_rf_rd: 1536\n",
      "\tpe_rf_wr: 512\n",
      "\tpost_tr_alu_comp: 1792\n",
      "\tpost_tr_rf_rd: 1152\n",
      "\tpost_tr_ifmap_rf_wr: 1152\n",
      "/tb/chip/ifmap_glb: \n",
      "\tsize: (64, 4)\n",
      "\tifmap_glb_rd: 256\n",
      "\tifmap_glb_wr: 256\n",
      "/tb/chip/weight_glb: \n",
      "\tsize: (0, 0)\n",
      "\tweight_glb_rd: 0\n",
      "\tweight_glb_wr: 0\n",
      "/tb/chip/bias_glb: \n",
      "\tsize: (0, 0)\n",
      "\tbias_glb_rd: 0\n",
      "\tbias_glb_wr: 0\n",
      "/tb/chip/weight_noc: \n",
      "\tnoc_multicast: 512\n",
      "/tb/chip/ifmap_noc: \n",
      "\tnoc_multicast: 256\n",
      "/tb/chip/bias_noc: \n",
      "\tnoc_multicast: 8\n",
      "/tb/chip/post_tr_wr_noc: \n",
      "\tnoc_multicast: 512\n",
      "/tb/chip/post_tr_rd_noc: \n",
      "\tnoc_multicast: 128\n",
      "\n",
      "cyc 213: Success\n"
     ]
    }
   ],
   "source": [
    "from ws_2d_winograd_post_on.tb import WSArchTB\n",
    "\n",
    "ws_tb = WSArchTB()\n",
    "run_tb(ws_tb, verbose=False, dump_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winograd Transform - Pre & Post Processing On Chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifmap glb depth: 64\n",
      "weight glb depth: 0\n",
      "ifmaps:  [[[  1  -9   8   6]\n",
      "  [  5   7 -29   8]\n",
      "  [ 18   4   1   6]\n",
      "  [  3   6   0  -7]]\n",
      "\n",
      " [[-10  -9 -13 -10]\n",
      "  [ 17   7  -6  -3]\n",
      "  [  1  -6   0   7]\n",
      "  [  0   3   8  -2]]\n",
      "\n",
      " [[  2  -3   0  -3]\n",
      "  [ -5   1   5   1]\n",
      "  [  4  -7 -12   4]\n",
      "  [  6   0  13   9]]\n",
      "\n",
      " [[ 26  -2  -9  -7]\n",
      "  [ -5   4 -21  13]\n",
      "  [ -2  -2 -10  -1]\n",
      "  [  0  -1   3  -5]]]\n",
      "weights:  [[[[ -8   5   0   1  10 -10  -8  12]\n",
      "   [-14 -13   8   2   1   0   0   0]\n",
      "   [ 13  -3  -1  17   0  22  -1  13]\n",
      "   [-16   1 -15   8 -12   2  -2 -11]]\n",
      "\n",
      "  [[-16  -5  17  -2   9   0   8 -18]\n",
      "   [ -4   9  -1   0  -4  11   2   0]\n",
      "   [  6   5   2  15   0   2  -6   1]\n",
      "   [ 15  -6 -11   9  -1   0   0   0]]\n",
      "\n",
      "  [[  8  -8 -10   0 -16 -13  18   7]\n",
      "   [  0  12 -10  -3   6   8   5 -25]\n",
      "   [ -9   4  -3  25   9   5 -11   0]\n",
      "   [  2  11   8  10  -9  14 -13  -5]]]\n",
      "\n",
      "\n",
      " [[[  4  -1 -10  -8 -15   5  12  -1]\n",
      "   [ -4 -14   9  22 -17 -10  -6  -5]\n",
      "   [  2  16  10   5  -7 -11  -7  15]\n",
      "   [  0  -4  -1   8 -13  14   1  -2]]\n",
      "\n",
      "  [[  4   2  -3  -2  -8   6  -5  -9]\n",
      "   [  1  13   0  -6   4  19 -14   3]\n",
      "   [  2  11   9  -1 -16   8  -8  -9]\n",
      "   [ 11  -9  14   3   3   3 -16 -17]]\n",
      "\n",
      "  [[  2   5   0  -8   0   0  -9  10]\n",
      "   [-17   5   3  10 -10   1  21   6]\n",
      "   [  1   5   0  21   9   0   2  -3]\n",
      "   [ 12 -14 -16  14  21   4   1   6]]]\n",
      "\n",
      "\n",
      " [[[ -6   1   0   6 -15  -5   8  -6]\n",
      "   [ -9  20   0  -5 -16   7   6  -2]\n",
      "   [-11   0  -8  -9  -1 -10   2   6]\n",
      "   [ -8 -13  15  -9  -6   2   5  -2]]\n",
      "\n",
      "  [[  4  -4  -9  14  24  16   1  18]\n",
      "   [  3  -4   4   0  -9  -8   8 -18]\n",
      "   [  6 -16 -21 -18  19  -1   0  14]\n",
      "   [  9 -13   8   1  -3   0  12  -8]]\n",
      "\n",
      "  [[  4   0 -17  -8   1  12  10   5]\n",
      "   [ -8  18   2 -10  -1   8   0   8]\n",
      "   [ 11   4  -8   1   0  18 -16  -1]\n",
      "   [ -5   3 -24  11   0 -18  -3   6]]]]\n",
      "biases:  [-15   0 -10  -5   0   1  -4   2]\n",
      "reference orig conv:  [[[ -254   229   128  -571  -683    88    82    28]\n",
      "  [  546  -138  -541   543  1189   232  -261   631]\n",
      "  [  -69  -206  -110    48  -717   861   133  -798]\n",
      "  [   15  -259  -324  -244  -274   170   207   143]]\n",
      "\n",
      " [[  142   -40  -192  -605  -219  -418   506   472]\n",
      "  [  265  -404  -976  -485   349   -98   469  -248]\n",
      "  [ -781  -107  -208   -30  -179  -507   337  -995]\n",
      "  [ -128  -215   -73  -109   400   341   -44   225]]\n",
      "\n",
      " [[ -268     4  -554   344   201  -609   752   639]\n",
      "  [  -89   198  1142  -153  -804  -425   452 -1078]\n",
      "  [   10  -187   542   767   545  -151  -244   -94]\n",
      "  [  242   121  -172   -32   -69   598  -289  -478]]\n",
      "\n",
      " [[  -99  -238  -360  -135   106   161    35   -24]\n",
      "  [  515  -497  -321  -713  -109   -54   299   217]\n",
      "  [ -198  -606  -200   481    21   369   157  -373]\n",
      "  [ -122    71  -225   -21   110  -173    65  -326]]]\n",
      "reference winograd:  [[[ -255   226   125  -573  -685    86    80    24]\n",
      "  [  547  -138  -541   544  1189   232  -260   632]\n",
      "  [  -73  -208  -112    45  -719   858   131  -799]\n",
      "  [   16  -259  -324  -244  -274   170   208   144]]\n",
      "\n",
      " [[  142   -40  -192  -604  -219  -417   508   474]\n",
      "  [  265  -404  -976  -485   348   -97   469  -248]\n",
      "  [ -781  -106  -208   -28  -179  -507   338  -994]\n",
      "  [ -128  -216   -72  -109   400   341   -45   225]]\n",
      "\n",
      " [[ -272     2  -556   341   198  -613   749   637]\n",
      "  [  -90   199  1143  -153  -804  -424   452 -1077]\n",
      "  [    8  -188   541   765   544  -153  -247   -97]\n",
      "  [  241   122  -171   -32   -69   599  -287  -478]]\n",
      "\n",
      " [[  -99  -236  -359  -135   105   162    36   -24]\n",
      "  [  515  -497  -320  -713  -109   -54   298   218]\n",
      "  [ -198  -604  -200   481    22   370   157  -372]\n",
      "  [ -122    71  -225   -21   110  -173    65  -327]]]\n",
      "ifmap glb_size:  64\n",
      "Num PEs:  32\n",
      "Num pre transform ifmap blocks:  16\n",
      "Num pre transform weights blocks:  32\n",
      "Num post transform blocks:  32\n",
      "image size:  (4, 4)\n",
      "filter size:  (3, 3)\n",
      "input channels:  4\n",
      "output channels:  8\n",
      "/tb: \n",
      "\tpe_comp_energy: 4096\n",
      "\ttr_alu_comp_energy: 5376\n",
      "\tdram_mem_acc: 488\n",
      "\tglb_mem_acc: 1536\n",
      "\trf_mem_acc: 11232\n",
      "\ttotal_mem_acc: 13256\n",
      "\ttotal_noc_multicasts: 2472\n",
      "\tdram_energy: 97600\n",
      "\tglb_energy: 9216\n",
      "\trf_energy: 11232\n",
      "\tdata_energy: 118048\n",
      "\tcomp_energy: 9472\n",
      "\ttotal_energy: 127520\n",
      "/tb/chip: \n",
      "\tdram_rd: 360\n",
      "\tdram_wr: 128\n",
      "\tpe_mac: 2048\n",
      "\tpe_chn_pop: 1536\n",
      "\tpe_chn_push: 2048\n",
      "\tpe_rf_rd: 1536\n",
      "\tpe_rf_wr: 512\n",
      "\tpre_tr_ifmap_alu_comp: 1024\n",
      "\tpre_tr_ifmap_rf_rd: 1216\n",
      "\tpre_tr_ifmap_rf_wr: 1312\n",
      "\tpre_tr_weights_alu_comp: 2560\n",
      "\tpre_tr_weights_rf_rd: 2432\n",
      "\tpre_tr_weights_rf_wr: 1920\n",
      "\tpost_tr_alu_comp: 1792\n",
      "\tpost_tr_rf_rd: 1152\n",
      "\tpost_tr_rf_wr: 1152\n",
      "/tb/chip/ifmap_glb: \n",
      "\tsize: (64, 4)\n",
      "\tifmap_glb_rd: 256\n",
      "\tifmap_glb_wr: 256\n",
      "/tb/chip/weight_glb: \n",
      "\tsize: (0, 0)\n",
      "\tweight_glb_rd: 512\n",
      "\tweight_glb_wr: 512\n",
      "/tb/chip/bias_glb: \n",
      "\tsize: (0, 0)\n",
      "\tbias_glb_rd: 0\n",
      "\tbias_glb_wr: 0\n",
      "/tb/chip/weight_noc: \n",
      "\tnoc_multicast: 512\n",
      "/tb/chip/ifmap_noc: \n",
      "\tnoc_multicast: 256\n",
      "/tb/chip/bias_noc: \n",
      "\tnoc_multicast: 8\n",
      "/tb/chip/post_tr_wr_noc: \n",
      "\tnoc_multicast: 512\n",
      "/tb/chip/post_tr_rd_noc: \n",
      "\tnoc_multicast: 128\n",
      "/tb/chip/pre_tr_ifmap_rd_noc: \n",
      "\tnoc_multicast: 256\n",
      "/tb/chip/pre_tr_weights_wr_noc: \n",
      "\tnoc_multicast: 288\n",
      "/tb/chip/pre_tr_weights_rd_noc: \n",
      "\tnoc_multicast: 512\n",
      "\n",
      "cyc 192: Success\n"
     ]
    }
   ],
   "source": [
    "from ws_2d_winograd_on_chip.tb import WSArchTB\n",
    "\n",
    "ws_tb = WSArchTB()\n",
    "run_tb(ws_tb, verbose=False, dump_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
